============================= test session starts =============================
platform win32 -- Python 3.12.6, pytest-8.3.4, pluggy-1.5.0 -- C:\Python312\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\cabra\Projects\LifeOS
configfile: pytest.ini
plugins: anyio-4.7.0, asyncio-1.3.0, cov-6.2.1, mockito-0.0.4
asyncio: mode=Mode.STRICT, debug=False, asyncio_default_fixture_loop_scope=function, asyncio_default_test_loop_scope=function
collecting ... collected 3 items

runtime/tests/orchestration/missions/test_loop_acceptance.py::test_crash_and_resume FAILED [ 33%]
runtime/tests/orchestration/missions/test_loop_acceptance.py::test_acceptance_oscillation FAILED [ 66%]
runtime/tests/orchestration/missions/test_loop_acceptance.py::test_verify_terminal_packet_structure FAILED [100%]

================================== FAILURES ===================================
____________________________ test_crash_and_resume ____________________________

acceptance_context = MissionContext(repo_root=WindowsPath('C:/Users/cabra/AppData/Local/Temp/pytest-of-cabra/pytest-628/test_crash_and_resume0/repo'), baseline_commit='abc', run_id='acc_run', operation_executor=None, journal=None, metadata={})
mock_subs = (<MagicMock name='DesignMission' id='1391909887136'>, <MagicMock name='BuildMission' id='1391910252768'>, <MagicMock name='ReviewMission' id='1391910256560'>, <MagicMock name='StewardMission' id='1391910473120'>)

    def test_crash_and_resume(acceptance_context, mock_subs):
        D, B, R, S = mock_subs
    
        # Run 1: Fails at Attempt 1 (Crash/Interruption simulated by exception or just fail)
        # We simulate a "System Exit" after Attempt 1 is recorded?
        # Or simpler: Attempt 1 fails standardly, we verify Ledger has it.
        # Then we run again, verify it picks up at Attempt 2.
    
        # Setup Run 1 behaviours
        D.return_value.run.return_value = MissionResult(True, MissionType.DESIGN, outputs={"build_packet": {"goal":"g"}}, evidence={"usage":{"total":1}})
    
        # Attempt 1: Review Rejection (Retry)
        B.return_value.run.return_value = MissionResult(True, MissionType.BUILD, outputs={"review_packet": {"payload": {"content": "diff1"}}}, evidence={"usage":{"total":1}})
        R.return_value.run.return_value = MissionResult(True, MissionType.REVIEW, outputs={"verdict": "rejected"}, evidence={"usage":{"total":1}})
    
        mission = AutonomousBuildCycleMission()
        inputs = {"task_spec": "resume_test"}
    
        # We want to simulate a crash *after* the attempt is recorded but *before* the loop finishes.
        # But the loop runs until termination.
        # To simulate crash, we can have the Policy raise an exception on Attempt 2?
        # Or just let it run 1 attempt and fail?
        # Let's let it run 1 attempt, check ledger, then run again.
    
        # To stop it after 1 attempt, we can mock Policy? No, integration test.
        # We can use a side effect on Build to raise SystemExit on 2nd call?
    
        B.return_value.run.side_effect = [
            MissionResult(True, MissionType.BUILD, outputs={"review_packet": {"payload": {"content": "diff1"}}}, evidence={"usage":{"total":1}}),
            KeyboardInterrupt("Simulate Crash")
        ]
    
        try:
            mission.run(acceptance_context, inputs)
        except KeyboardInterrupt:
            pass
    
        # Verify Ledger has Attempt 1
        ledger_path = acceptance_context.repo_root / "artifacts/loop_state/attempt_ledger.jsonl"
        with open(ledger_path) as f:
            lines = f.readlines()
>           assert len(lines) == 2 # Header + 1 record
E           assert 1 == 2
E            +  where 1 = len(['{"type": "header", "schema_version": "v1.0", "policy_hash": "phase_a_hardcoded_v1", "handoff_hash": "05ffa117091561c24e996b237595c7b76a46d8a556de944099b6d1dc4286c31f", "run_id": "acc_run"}\n'])

runtime\tests\orchestration\missions\test_loop_acceptance.py:69: AssertionError
_________________________ test_acceptance_oscillation _________________________

acceptance_context = MissionContext(repo_root=WindowsPath('C:/Users/cabra/AppData/Local/Temp/pytest-of-cabra/pytest-628/test_acceptance_oscillation0/repo'), baseline_commit='abc', run_id='acc_run', operation_executor=None, journal=None, metadata={})
mock_subs = (<MagicMock name='DesignMission' id='1391910738096'>, <MagicMock name='BuildMission' id='1391910734400'>, <MagicMock name='ReviewMission' id='1391910739344'>, <MagicMock name='StewardMission' id='1391910743808'>)

    def test_acceptance_oscillation(acceptance_context, mock_subs):
        D, B, R, S = mock_subs
    
        D.return_value.run.return_value = MissionResult(True, MissionType.DESIGN, outputs={"build_packet": {"goal":"g"}}, evidence={"usage":{"total":1}})
    
        # A -> B -> A
        # We need 3 attempts.
        # 1: diffA (Rejected)
        # 2: diffB (Rejected)
        # 3: diffA (Rejected -> Oscillation detected)
    
        # Mock Build outputs
        B.return_value.run.side_effect = [
            MissionResult(True, MissionType.BUILD, outputs={"review_packet": {"payload": {"content": "diffA"}}}, evidence={"usage":{"total":1}}),
            MissionResult(True, MissionType.BUILD, outputs={"review_packet": {"payload": {"content": "diffB"}}}, evidence={"usage":{"total":1}}),
            MissionResult(True, MissionType.BUILD, outputs={"review_packet": {"payload": {"content": "diffA"}}}, evidence={"usage":{"total":1}}),
        ]
    
        # Mock Review to always reject
        R.return_value.run.return_value = MissionResult(True, MissionType.REVIEW, outputs={"verdict": "rejected"}, evidence={"usage":{"total":1}})
    
        mission = AutonomousBuildCycleMission()
        result = mission.run(acceptance_context, {"task_spec": "osc_test"})
    
        assert result.success is False
>       assert result.error == TerminalReason.OSCILLATION_DETECTED.value
E       AssertionError: assert None == 'oscillation_detected'
E        +  where None = MissionResult(success=False, mission_type=<MissionType.AUTONOMOUS_BUILD_CYCLE: 'autonomous_build_cycle'>, outputs={}, executed_steps=[], error=None, escalation_reason='Design rejected: rejected', evidence={}).error
E        +  and   'oscillation_detected' = <TerminalReason.OSCILLATION_DETECTED: 'oscillation_detected'>.value
E        +    where <TerminalReason.OSCILLATION_DETECTED: 'oscillation_detected'> = TerminalReason.OSCILLATION_DETECTED

runtime\tests\orchestration\missions\test_loop_acceptance.py:126: AssertionError
____________________ test_verify_terminal_packet_structure ____________________

acceptance_context = MissionContext(repo_root=WindowsPath('C:/Users/cabra/AppData/Local/Temp/pytest-of-cabra/pytest-628/test_verify_terminal_packet_st0/repo'), baseline_commit='abc', run_id='acc_run', operation_executor=None, journal=None, metadata={})
mock_subs = (<MagicMock name='DesignMission' id='1391910993840'>, <MagicMock name='BuildMission' id='1391910989376'>, <MagicMock name='ReviewMission' id='1391910994000'>, <MagicMock name='StewardMission' id='1391910997936'>)

    def test_verify_terminal_packet_structure(acceptance_context, mock_subs):
        # Just force a budget exhaustion to check packet fields
        D, B, R, S = mock_subs
        D.return_value.run.return_value = MissionResult(True, MissionType.DESIGN, outputs={"build_packet": {"goal":"g"}}, evidence={"usage":{"total":1}})
        B.return_value.run.return_value = MissionResult(True, MissionType.BUILD, outputs={"review_packet": {"payload": {"content": "u"}}}, evidence={"usage":{"total":1}})
        R.return_value.run.return_value = MissionResult(True, MissionType.REVIEW, outputs={"verdict": "rejected"}, evidence={"usage":{"total":1}})
    
        # Small budget to fail fast
        with patch("runtime.orchestration.missions.autonomous_build_cycle.BudgetController") as MockBudget:
            MockBudget.return_value.check_budget.return_value = (True, TerminalReason.BUDGET_EXHAUSTED.value)
    
            mission = AutonomousBuildCycleMission()
            mission.run(acceptance_context, {"task_spec": "pkt"})
    
        term_path = acceptance_context.repo_root / "artifacts/CEO_Terminal_Packet.md"
>       with open(term_path) as f:
E       FileNotFoundError: [Errno 2] No such file or directory: 'C:\\Users\\cabra\\AppData\\Local\\Temp\\pytest-of-cabra\\pytest-628\\test_verify_terminal_packet_st0\\repo\\artifacts\\CEO_Terminal_Packet.md'

runtime\tests\orchestration\missions\test_loop_acceptance.py:151: FileNotFoundError
=========================== short test summary info ===========================
FAILED runtime/tests/orchestration/missions/test_loop_acceptance.py::test_crash_and_resume - assert 1 == 2
 +  where 1 = len(['{"type": "header", "schema_version": "v1.0", "policy_hash": "phase_a_hardcoded_v1", "handoff_hash": "05ffa117091561c24e996b237595c7b76a46d8a556de944099b6d1dc4286c31f", "run_id": "acc_run"}\n'])
FAILED runtime/tests/orchestration/missions/test_loop_acceptance.py::test_acceptance_oscillation - AssertionError: assert None == 'oscillation_detected'
 +  where None = MissionResult(success=False, mission_type=<MissionType.AUTONOMOUS_BUILD_CYCLE: 'autonomous_build_cycle'>, outputs={}, executed_steps=[], error=None, escalation_reason='Design rejected: rejected', evidence={}).error
 +  and   'oscillation_detected' = <TerminalReason.OSCILLATION_DETECTED: 'oscillation_detected'>.value
 +    where <TerminalReason.OSCILLATION_DETECTED: 'oscillation_detected'> = TerminalReason.OSCILLATION_DETECTED
FAILED runtime/tests/orchestration/missions/test_loop_acceptance.py::test_verify_terminal_packet_structure - FileNotFoundError: [Errno 2] No such file or directory: 'C:\\Users\\cabra\\AppData\\Local\\Temp\\pytest-of-cabra\\pytest-628\\test_verify_terminal_packet_st0\\repo\\artifacts\\CEO_Terminal_Packet.md'
============================== 3 failed in 0.96s ==============================
